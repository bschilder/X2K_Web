{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of alternative methods for kinase enrichment analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/schilder/Desktop/X2K_Web/Kinase_Enrichment_Comparisons\n"
     ]
    }
   ],
   "source": [
    "import X2Kweb_API as xweb\n",
    "\n",
    "import pandas as pd\n",
    "%pwd\n",
    "%cd Kinase_Enrichment_Comparisons\n",
    "\n",
    "import pickle\n",
    "with open(\"../../X2K_Summaries/General_Resources/synDict.pkl\", 'rb') as handle:\n",
    "    synDict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# :: X2K ::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import list of all kinases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize genes to HGNC symbols\n",
    "mapping = pd.read_table('../../X2K_Summaries/General_Resources/Moshe_mapping/mappingFile_2017.txt', header=None)\n",
    "greekLetters = pd.read_csv('../../X2K_Summaries/General_Resources/GreekLetter_Converter.csv', names=['Greek', 'Abbrev'], header=0 )\n",
    "greekLetters = greekLetters.apply(lambda x: x.str.strip('\\xa0'))\n",
    "\n",
    "def standardizeGeneSymbol(gene):\n",
    "    if gene.__contains__('AURORA'):\n",
    "        HGNC = 'AURK' + gene[-1]\n",
    "    elif any(substring in gene for substring in greekLetters['Greek']):\n",
    "        for letter in greekLetters['Greek']:\n",
    "            LETTER = letter.upper()\n",
    "            if gene.__contains__(LETTER):\n",
    "                HGNC = gene.replace(LETTER, greekLetters.loc[greekLetters['Greek']==letter,'Abbrev'].values[0] )\n",
    "    else:\n",
    "        HGNC = gene\n",
    "    if HGNC in mapping[0]:\n",
    "        HGNC = mapping.iloc[mapping[0]==HGNC, 1]\n",
    "    return HGNC\n",
    "\n",
    "# Get list of all kinases in KEA2018\n",
    "import pandas as pd\n",
    "KEA2018 = pd.read_csv('../../X2k_Databases/KINASE/KEA_2018/KEA2018_KINASES.csv', header=None)#pd.read_csv(\"KEA/UberKeaFile.csv\")\n",
    "KEA2018.head()\n",
    "allKinases = KEA2018.iloc[:,2].unique().tolist()\n",
    "\n",
    "# # Get list of unique kinases in KEA2018, standardized to HGNC symbols\n",
    "# def get_all_kinases():\n",
    "#     with open('allKinases_KEA2018.txt','w') as file:\n",
    "#         seen=[]\n",
    "#         for k in allKinases:\n",
    "#             HGNC = standardizeGeneSymbol(k)\n",
    "#             if HGNC not in seen:\n",
    "#                 file.write(HGNC+\"\\n\")\n",
    "#             seen.append(HGNC)\n",
    "#     return allKinases\n",
    "# allKinases = get_all_kinases()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run X2K Web with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OFF\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# UP genes\n",
    "kinase_file = 'Kinase_Perturbations_from_GEO_up.txt'\n",
    "save_file = 'X2K_kinasePvalues_UP.txt'\n",
    "X2K_UP = xweb.run_X2K_allGenes(kinase_file, save_file, verbose=True, replaceNAs=False, outputValues='pvalue')\n",
    "\n",
    "# DN Genes\n",
    "kinase_file = 'Kinase_Perturbations_from_GEO_down.txt'\n",
    "save_file = 'X2K_kinasePvalues_DN.txt'\n",
    "X2K_DN = xweb.run_X2K_allGenes(kinase_file, save_file, verbose=True, replaceNAs=False, outputValues='pvalue')\n",
    "\"\"\"\n",
    "print(\"OFF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OFF\n"
     ]
    }
   ],
   "source": [
    "# Run X2K Web with ranks from z-scores of -log(val)\n",
    "\n",
    "\"\"\"\n",
    "# UP genes\n",
    "kinase_file = 'Kinase_Perturbations_from_GEO_up.txt'\n",
    "save_file = 'X2K_kinaseRanks_negLogZRank_UP.txt'\n",
    "#X2K_UP_negLog = xweb.run_X2K_allGenes(kinase_file, save_file, verbose=True, replaceNAs=False, rankingMethod='-log(pvalue)')\n",
    "\n",
    "X2K_UP_negLog = pd.read_table('X2K_kinaseRanks_negLogZRank_UP.txt', index_col=False).fillna(0)\n",
    "# Add absent perturbed kinases (also with -log(pvalue)==0)\n",
    "X2K_UP_negLog = add_absent_perturbed(X2K_UP_negLog)\n",
    "\n",
    "\n",
    "\n",
    "# DN genes\n",
    "kinase_file = 'Kinase_Perturbations_from_GEO_down.txt'\n",
    "save_file = 'X2K_kinaseRanks_negLogZRank_DN.txt'\n",
    "#X2K_DN_negLog = xweb.run_X2K_allGenes(kinase_file, save_file, verbose=True, replaceNAs=False, rankingMethod='-log(pvalue)')\n",
    "\n",
    "X2K_DN_negLog = pd.read_table('X2K_kinaseRanks_negLogZRank_DN.txt', index_col=False)\n",
    "# Fill Nas with -log(pvalue)==0\n",
    "X2K_DN_negLog.fillna(0, inplace=True)\n",
    "# Add absent perturbed kinases (also with -log(pvalue)==0)\n",
    "X2K_DN_negLog = add_absent_perturbed(X2K_DN_negLog)\n",
    "\n",
    "\"\"\"\n",
    "print(\"OFF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# :: KEA ::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alex's version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef run_KEA(input_line):\\n    directory=\\'KEA/\\'\\n    import time\\n    import socket\\n    HOST = \"localhost\"\\n    PORT3 = 5002\\n    start_time = time.time()\\n    \\n    sock2 = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\\n    sock2.connect((HOST, PORT3))\\n\\n    buffer_size = 1024\\n    allData3 = \\',\\'.join([input_line[0]]+input_line[2:])\\n\\n    print(\"Running KEA...\")\\n    kea_string = \\';\\'.join([\"run\", \\'pvalue\\', \\'humanarchs4\\', \\'KP\\',  \\'10000\\'])\\n    print(\"KEA Parameters:   \"+kea_string)\\n    kea_parameters = kea_string + \"\\n\"+allData3+\"messageComplete\\n\"\\n    kea_parameters.replace(\"messageComplete\\n\", \"\")\\n    sock2.sendall(bytes(kea_parameters+\"\\n\", \\'utf-8\\'))\\n\\n    while 1:\\n        #print(\"d: \"+data)\\n        data = sock2.recv(buffer_size).decode(\"utf-8\")\\n        allData3 = allData3 + data\\n        if allData3.endswith(\"messageComplete\\n\"):\\n            break\\n    \\n    allData3.replace(\"messageComplete\\n\", \"\")\\n    sock2.send(bytes(\"kill\\n\", \\'utf-8\\'))\\n    sock2.close()\\n    \\n    allData3 = allData3.replace(\"messageComplete\\n\", \"\").replace(kea_parameters, \"\")\\n    \\n    text_file = open(directory+\"output/kea_out.txt\", \"w\")\\n    text_file.write(allData3)\\n    text_file.close()\\n\\n    time.time() - start_time\\n    return allData3\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def run_KEA(input_line):\n",
    "    directory='KEA/'\n",
    "    import time\n",
    "    import socket\n",
    "    HOST = \"localhost\"\n",
    "    PORT3 = 5002\n",
    "    start_time = time.time()\n",
    "    \n",
    "    sock2 = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    sock2.connect((HOST, PORT3))\n",
    "\n",
    "    buffer_size = 1024\n",
    "    allData3 = ','.join([input_line[0]]+input_line[2:])\n",
    "\n",
    "    print(\"Running KEA...\")\n",
    "    kea_string = ';'.join([\"run\", 'pvalue', 'humanarchs4', 'KP',  '10000'])\n",
    "    print(\"KEA Parameters:   \"+kea_string)\n",
    "    kea_parameters = kea_string + \"\\n\"+allData3+\"messageComplete\\n\"\n",
    "    kea_parameters.replace(\"messageComplete\\n\", \"\")\n",
    "    sock2.sendall(bytes(kea_parameters+\"\\n\", 'utf-8'))\n",
    "\n",
    "    while 1:\n",
    "        #print(\"d: \"+data)\n",
    "        data = sock2.recv(buffer_size).decode(\"utf-8\")\n",
    "        allData3 = allData3 + data\n",
    "        if allData3.endswith(\"messageComplete\\n\"):\n",
    "            break\n",
    "    \n",
    "    allData3.replace(\"messageComplete\\n\", \"\")\n",
    "    sock2.send(bytes(\"kill\\n\", 'utf-8'))\n",
    "    sock2.close()\n",
    "    \n",
    "    allData3 = allData3.replace(\"messageComplete\\n\", \"\").replace(kea_parameters, \"\")\n",
    "    \n",
    "    text_file = open(directory+\"output/kea_out.txt\", \"w\")\n",
    "    text_file.write(allData3)\n",
    "    text_file.close()\n",
    "\n",
    "    time.time() - start_time\n",
    "    return allData3\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X2K Web Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    1. name of the kinase\\n    2. number of substrates in the input gene-list\\n    3. number of genes that are substrates of the kinase\\n    4. the fraction of genes that are substrates compared to total number of genes in gene-list\\n    5. the fraction of genes that are substrates compared to total number of genes in background\\n    6. difference between the background fraction and the substrate-list fraction\\n    7. p-value computed using the Fisher Test\\n    8. rank computed using z-test\\n    9. combined score computed from p-value and rank\\n    10. list of substrates separated by a semi-colon\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## KEA CSV OUTPUT FORMAT\n",
    "\n",
    "\"\"\"\n",
    "    1. name of the kinase\n",
    "    2. number of substrates in the input gene-list\n",
    "    3. number of genes that are substrates of the kinase\n",
    "    4. the fraction of genes that are substrates compared to total number of genes in gene-list\n",
    "    5. the fraction of genes that are substrates compared to total number of genes in background\n",
    "    6. difference between the background fraction and the substrate-list fraction\n",
    "    7. p-value computed using the Fisher Test\n",
    "    8. rank computed using z-test\n",
    "    9. combined score computed from p-value and rank\n",
    "    10. list of substrates separated by a semi-colon\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OFF\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "For X2K and KEA, whenever the kinase-enrichment couldn't find any overlap between the substrates of a given kinase \n",
    "and the genes in the input list, KEA returns 'NaN' for that kinase.\n",
    "-Alternatively, you can randomly assign a remaining rank \n",
    "\"\"\"\n",
    " \n",
    "\n",
    "# For both X2K and KEA\n",
    "def absent_perturbed_kinases(DF):\n",
    "    perturbedKinases = set([x.split('_')[0] for x in DF.columns[1:]])\n",
    "    absentPerturbed=[]\n",
    "    for pert in perturbedKinases:\n",
    "        syns = synDict[pert]\n",
    "        overlap = set(syns).intersection(set(DF['Kinase']))\n",
    "        if len(overlap)==0:\n",
    "            absentPerturbed.append(pert)\n",
    "    return absentPerturbed\n",
    "\n",
    "\n",
    "\n",
    "def replace_NAs_with_random_rank(DF):\n",
    "    # Get list of perturbed kinases that are absent from the output file \n",
    "    absentPerturbed = absent_perturbed_kinases(DF)\n",
    "    newDF = pd.concat([DF['Kinase'], pd.Series(absentPerturbed).rename('Kinase')]).reset_index()['Kinase']\n",
    "    # Assign ranks\n",
    "    import math\n",
    "    from random import shuffle\n",
    "    for col in DF.iloc[:,1:]:\n",
    "        newRanks=[]\n",
    "        DFcol = DF[col]\n",
    "        print(col)\n",
    "        # Create lists of remaining ranks\n",
    "        maxRank = int(max(DFcol.dropna()))\n",
    "        remainingRanks = list(range(maxRank+1,len(newDF)))\n",
    "        shuffle(remainingRanks)\n",
    "        # Replace any NAs with random rank\n",
    "        NAcount=0\n",
    "        for inputRank in DFcol:\n",
    "            if math.isnan(inputRank):\n",
    "                #newRanks.append( np.random.choice(remainingRanks, 1, replace=False)[0] )\n",
    "                newRanks.append( remainingRanks[NAcount] )\n",
    "                NAcount+=1\n",
    "            else:\n",
    "                newRanks.append( int(inputRank) )\n",
    "        for ap in absentPerturbed:\n",
    "            newRanks.append(remainingRanks[NAcount])\n",
    "            NAcount+=1\n",
    "        newCol = pd.Series(newRanks, name=col)\n",
    "        newDF = pd.concat([newDF, newCol], axis=1) \n",
    "    return newDF \n",
    "\n",
    "\n",
    "\n",
    "#----------------------\n",
    "# KEA-specific\n",
    "import pandas as pd\n",
    "import os \n",
    "from time import sleep\n",
    "\n",
    "def create_geneList_file(geneList):\n",
    "    with open('KEA/geneList.txt','w') as file:\n",
    "        for g in geneList:\n",
    "            file.write(g+'\\n')\n",
    "\n",
    "#create_DF_from_KEAoutput  \n",
    "def create_DF_from_KEAoutput(expt, finalDF):\n",
    "    KEAout = pd.read_csv('KEA/KEA_output.csv', header=None, index_col=False)\n",
    "    KEAout.head()\n",
    "    KEAout.columns = ['Kinase','number of substrates in the input gene-list', 'number of genes that are substrates of the kinase',\\\n",
    "                      'fraction of genes that are substrates compared to total number of genes in gene-list',\\\n",
    "                      'fraction of genes that are substrates compared to total number of genes in background',\\\n",
    "                      'difference between the background fraction and the substrate-list fraction',\\\n",
    "                      'pvalue', 'ztest_rank', 'combined_score','substrates']\n",
    "    KEAout.index = KEAout['Kinase']\n",
    "    KEA_sort = KEAout.sort_values(by='pvalue')\n",
    "    KEA_sort[expt] = range(0,len(KEA_sort))\n",
    "    newDF = KEA_sort[['Kinase',expt]]\n",
    "    finalDF = finalDF.merge(newDF, on='Kinase', how='outer')\n",
    "    return finalDF\n",
    "\n",
    "def return_negLog(expt, finalDF):\n",
    "    KEAout = pd.read_csv('KEA/KEA_output.csv', header=None, index_col=False)\n",
    "    KEAout.columns = ['Kinase','number of substrates in the input gene-list', 'number of genes that are substrates of the kinase',\\\n",
    "                      'fraction of genes that are substrates compared to total number of genes in gene-list',\\\n",
    "                      'fraction of genes that are substrates compared to total number of genes in background',\\\n",
    "                      'difference between the background fraction and the substrate-list fraction',\\\n",
    "                      'pvalue', 'ztest_rank', 'combined_score','substrates']\n",
    "    KEAout.index = KEAout['Kinase']\n",
    "    KEAout.head()\n",
    "    # Create -log(pvalue)\n",
    "    import numpy as np\n",
    "    KEAout['-log(pvalue)'] = -np.log(pd.to_numeric(KEAout['pvalue']))\n",
    "    KEA_sort = KEAout.sort_values(by=['-log(pvalue)'])[['Kinase','-log(pvalue)']] #** Select values to put in newDF\n",
    "    KEA_sort.columns = ['Kinase', expt]\n",
    "    finalDF = finalDF.merge(KEA_sort, on='Kinase', how='outer')\n",
    "    return finalDF\n",
    " \n",
    "   \n",
    "    \n",
    "def run_KEA_old(inputGMT, KEA_summary_file, replaceNAs=True):\n",
    "    with open(inputGMT) as file:\n",
    "        input_GMT = file.readlines()\n",
    "    #input_GMT = input_GMT[0:10]\n",
    "    finalDF = pd.DataFrame(columns=['Kinase'],dtype=float)\n",
    "    for line in input_GMT:\n",
    "        # Delete old files\n",
    "        try:\n",
    "            os.remove('KEA/KEA_output.csv')\n",
    "            os.remove('KEA/geneList.txt')\n",
    "        except:\n",
    "            print(\"No files to delete\")\n",
    "        while os.path.exists('KEA/geneList.txt') or os.path.exists('KEA/KEA_output.csv'):\n",
    "            sleep(.5)\n",
    "        \n",
    "        # Create gene list\n",
    "        lineSp = line.split('\\t')\n",
    "        expt = lineSp[0]\n",
    "        genes = [x.strip(',1.0') for x in lineSp[2:-1]]\n",
    "        print(\"Processing: \"+expt)\n",
    "        # Create gene list txt file\n",
    "        print(expt+': Creating genList file')\n",
    "        create_geneList_file(genes)\n",
    "        print('Waiting for KEA_output')\n",
    "        while not os.path.exists('KEA/geneList.txt'):\n",
    "            sleep(.5) \n",
    "        # Run KEA command line\n",
    "        # result = subprocess.run(['/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Home/bin/java','-jar',\\\n",
    "        #                          'KEA/KEA-1.5-SNAPSHOT-jar-with-dependencies.jar','KEA/UberKeaFile.csv',\\\n",
    "        #                          'KEA/geneList.txt KEA/KEA_output.csv'] )\n",
    "        # result.stdout.decode('utf-8')\n",
    "        print('Running KEA')\n",
    "        os.system('/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Home/bin/java '+\\\n",
    "                  ' -jar'+' KEA/KEA-1.5-SNAPSHOT-jar-with-dependencies.jar'+' ../../X2K_Databases/KINASE/KEA_2018/KEA2018_KINASES.csv'+\\\n",
    "                  ' KEA/geneList.txt'+ ' KEA/KEA_output.csv')\n",
    "        # Sleep until the file is ready\n",
    "        print('Waiting for KEA_output')\n",
    "        while not os.path.exists('KEA/KEA_output.csv'):\n",
    "            sleep(.5)\n",
    "            \n",
    "        # Read in KEA output and process\n",
    "        print(expt+' : Creating dataframe')\n",
    "        \n",
    "        finalDF = return_negLog(expt, finalDF) #*** Control whether you what values are in final DF\n",
    "        if replaceNAs==True:\n",
    "            finalDF = replace_NAs_with_random_rank(finalDF)\n",
    "        \n",
    "    finalDF.to_csv(KEA_summary_file, sep='\\t', header=True, index=None, na_rep='NA')\n",
    "    return finalDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run KEA with Each Kinase Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_KEA_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Fill NAs in X2K results files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# UP\\nX2K_UP = pd.read_table('X2K_kinaseRanks_UP.txt', index_col=False)\\nX2K_filled_UP = replace_NAs_with_random_rank(X2K_UP) \\nX2K_filled_UP.to_csv('X2K_output_NAsfilled_UP.txt', sep='\\t', header=True, index=None, na_rep='NA')\\n\\n# DN\\nX2K_DN = pd.read_table('X2K_kinaseRanks_DN.txt', index_col=False)\\nX2K_filled_DN = replace_NAs_with_random_rank(X2K_DN)\\nX2K_filled_DN.to_csv('X2K_output_NAsfilled_DN.txt', sep='\\t', header=True, index=None, na_rep='NA')\\n\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# UP\n",
    "X2K_UP = pd.read_table('X2K_kinaseRanks_UP.txt', index_col=False)\n",
    "X2K_filled_UP = replace_NAs_with_random_rank(X2K_UP) \n",
    "X2K_filled_UP.to_csv('X2K_output_NAsfilled_UP.txt', sep='\\t', header=True, index=None, na_rep='NA')\n",
    "\n",
    "# DN\n",
    "X2K_DN = pd.read_table('X2K_kinaseRanks_DN.txt', index_col=False)\n",
    "X2K_filled_DN = replace_NAs_with_random_rank(X2K_DN)\n",
    "X2K_filled_DN.to_csv('X2K_output_NAsfilled_DN.txt', sep='\\t', header=True, index=None, na_rep='NA')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run KEA (and fill NAs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OFF\n"
     ]
    }
   ],
   "source": [
    "# KEA_UP = run_KEA_old(inputGMT='Kinase_Perturbations_from_GEO_up.txt', KEA_summary_file='KEA_output_NAsfilled_UP.txt', replaceNAs=True)\n",
    "# KEA_DN = run_KEA_old(inputGMT='Kinase_Perturbations_from_GEO_down.txt', KEA_summary_file='KEA_output_NAsfilled_DN.txt', replaceNAs=True)\n",
    "\n",
    "\"\"\"\n",
    "# Get -log(pvalues)\n",
    "## UP\n",
    "KEA_UP = run_KEA_old(inputGMT='Kinase_Perturbations_from_GEO_up.txt', KEA_summary_file='KEA_results_negLogPval_UP.txt', replaceNAs=False)\n",
    "KEA_UP.fillna(0, inplace=True)\n",
    "## DN\n",
    "KEA_DN = run_KEA_old(inputGMT='Kinase_Perturbations_from_GEO_down.txt', KEA_summary_file='KEA_results_negLogPval_DN.txt', replaceNAs=False)\n",
    "KEA_DN.fillna(0, inplace=True)\n",
    "\"\"\"\n",
    "print(\"OFF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !!!!!!! Import Previously Processed Results !!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def absent_perturbed_kinases(DF):\n",
    "        perturbedKinases = set([x.split('_')[0] for x in DF.columns[1:]])\n",
    "        absentPerturbed=[]\n",
    "        for pert in perturbedKinases:\n",
    "            syns = synDict[pert]\n",
    "            overlap = set(syns).intersection(set(DF['Kinase']))\n",
    "            if len(overlap)==0:\n",
    "                absentPerturbed.append(pert)\n",
    "        return absentPerturbed\n",
    "\n",
    "\n",
    "def add_absent_perturbed(DF):\n",
    "    absent = absent_perturbed_kinases(DF)\n",
    "    emptyDF = pd.DataFrame(0.0, index= np.arange(len(absent)), columns=DF.columns)\n",
    "    emptyDF['Kinase'] = absent\n",
    "    newDF = pd.concat([DF, emptyDF])\n",
    "    newDF.index = range(0,len(newDF))\n",
    "    return newDF\n",
    "\n",
    "# DF=X2K_UP.copy()\n",
    "# def add_allKinases(DF): \n",
    "#     allKinases = get_all_kinases()\n",
    "#     newDF=pd.DataFrame()\n",
    "#     missingKinases=[]\n",
    "#     for k in allKinases:\n",
    "#         syns = synDict[k]\n",
    "#         overlap = set(syns).intersection(set(DF['Kinase']))\n",
    "#         if len(overlap)==0:\n",
    "#             missingKinases.append(k)\n",
    "#     emptyDF = pd.DataFrame(0.0, index= np.arange(len(missingKinases)), columns=DF.columns)\n",
    "#     emptyDF['Kinase'] = absent\n",
    "#     newDF = pd.concat([DF, emptyDF])\n",
    "#     newDF.index = range(0,len(newDF))\n",
    "\n",
    "\n",
    "def standardize_geneSymbols(DF):\n",
    "    newGenes=[]\n",
    "    for g in DF['Kinase'].tolist():\n",
    "        newGenes.append(standardizeGeneSymbol(g))\n",
    "    DF['Kinase'] = newGenes\n",
    "    return DF \n",
    "\n",
    "def import_fillNA_addMissingKinases(fileName,  standardize_genes=True, fillNAs=True, addAbsentKinases=True):\n",
    "    file = pd.read_table(fileName, index_col=False)\n",
    "    if standardize_genes==True:\n",
    "        file = standardize_geneSymbols(file)\n",
    "    if fillNAs==True:\n",
    "        file.fillna(0, inplace=True)\n",
    "    if addAbsentKinases==True:\n",
    "        file = add_absent_perturbed(file)\n",
    "    return file\n",
    "        \n",
    "        \n",
    "    \n",
    "# Import and correct data at the same time\n",
    "# X2K\n",
    "X2K_UP = import_fillNA_addMissingKinases('Results/X2K_results_negLogPval_UP.txt')\n",
    "X2K_DN = import_fillNA_addMissingKinases('Results/X2K_results_negLogPval_DN.txt')\n",
    "\n",
    "## KEA\n",
    "KEA_UP = import_fillNA_addMissingKinases('Results/KEA_results_negLogPval_UP.txt')\n",
    "KEA_DN = import_fillNA_addMissingKinases('Results/KEA_results_negLogPval_DN.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Ranks to Zscore Ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef zscore_Ranks(DF):\\n    newRanks_DF=pd.DataFrame()\\n    from scipy import stats\\n    rankDF =  DF.iloc[:,1:].copy()\\n    zscoreDF = pd.DataFrame(stats.zscore(rankDF, axis=1), columns=rankDF.columns)\\n    for col in zscoreDF:\\n        orderedCol = zscoreDF[col]\\n        orderedCol.index = DF['Kinase']\\n        # Assign new ranks based on zscores of old ranks\\n        orderedCol = orderedCol.sort_values()\\n        newRanks = pd.Series(data=range(0,len(orderedCol)), name=col, index=orderedCol.index)\\n        #Merge DFs on index\\n        newRanks_DF = pd.concat([newRanks_DF, newRanks], axis=1)\\n    #Add kinase col \\n    newKinaseCol = pd.Series(newRanks_DF.index, name='Kinase', index=newRanks_DF.index)\\n    zscoreRanks_DF = pd.concat([newKinaseCol, newRanks_DF ], axis=1)\\n    zscoreRanks_DF = zscoreRanks_DF.reset_index()\\n    del zscoreRanks_DF['index']\\n    return zscoreRanks_DF\\n\\n# Create Zscore DFs\\nX2K_UP_Zscore = zscore_Ranks(X2K_UP)\\nX2K_DN_Zscore = zscore_Ranks(X2K_DN)\\nKEA_UP_Zscore = zscore_Ranks(KEA_UP)\\nKEA_DN_Zscore = zscore_Ranks(KEA_DN)\\n\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def zscore_Ranks(DF):\n",
    "    newRanks_DF=pd.DataFrame()\n",
    "    from scipy import stats\n",
    "    rankDF =  DF.iloc[:,1:].copy()\n",
    "    zscoreDF = pd.DataFrame(stats.zscore(rankDF, axis=1), columns=rankDF.columns)\n",
    "    for col in zscoreDF:\n",
    "        orderedCol = zscoreDF[col]\n",
    "        orderedCol.index = DF['Kinase']\n",
    "        # Assign new ranks based on zscores of old ranks\n",
    "        orderedCol = orderedCol.sort_values()\n",
    "        newRanks = pd.Series(data=range(0,len(orderedCol)), name=col, index=orderedCol.index)\n",
    "        #Merge DFs on index\n",
    "        newRanks_DF = pd.concat([newRanks_DF, newRanks], axis=1)\n",
    "    #Add kinase col \n",
    "    newKinaseCol = pd.Series(newRanks_DF.index, name='Kinase', index=newRanks_DF.index)\n",
    "    zscoreRanks_DF = pd.concat([newKinaseCol, newRanks_DF ], axis=1)\n",
    "    zscoreRanks_DF = zscoreRanks_DF.reset_index()\n",
    "    del zscoreRanks_DF['index']\n",
    "    return zscoreRanks_DF\n",
    "\n",
    "# Create Zscore DFs\n",
    "X2K_UP_Zscore = zscore_Ranks(X2K_UP)\n",
    "X2K_DN_Zscore = zscore_Ranks(X2K_DN)\n",
    "KEA_UP_Zscore = zscore_Ranks(KEA_UP)\n",
    "KEA_DN_Zscore = zscore_Ranks(KEA_DN)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert values to zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_Zeros(DF):\n",
    "    # Drop all rows that ONLY have (0). Never appeared across any experiment\n",
    "    # Keeping the all 0s messes up the zscore\n",
    "    DFcols = DF.iloc[:,1:]\n",
    "    filteredDF = DF[(DFcols.T != 0).any()]\n",
    "    return filteredDF\n",
    "\n",
    "#DF = X2K_UP.copy()\n",
    "def values_to_zscores(DF, dropZeros=True):\n",
    "    if dropZeros==True:\n",
    "        df = drop_Zeros(DF).copy()\n",
    "    else:\n",
    "        df = DF.copy()\n",
    "    from scipy import stats\n",
    "    #df.index = df['Kinase']\n",
    "    df.index = range(0,len(df))\n",
    "    # 1. Shuffle around only the rows with -log(pval)==0 \n",
    "    ## to make sure there's no bias in their zscores (e.g. based on alphabetical order)\n",
    "    for col in df.iloc[:,1:]:\n",
    "        dfCol = df.loc[:,col]\n",
    "        #print(col)\n",
    "        # Get all the zeros\n",
    "        df0 = dfCol.loc[dfCol==0]\n",
    "        df0 = df0.sample(frac=1) # Shuffle \n",
    "        # Get all the non-zeros\n",
    "        dfNum = dfCol.loc[dfCol!=0]\n",
    "        # Recombine them and put back into df\n",
    "        df.loc[:,col] = pd.concat([dfNum, df0]) ###### here\n",
    "        \n",
    "    # 2. Now take zscore\n",
    "    DFsub  = df.iloc[:,1:]\n",
    "    zscoreDF = pd.DataFrame(stats.zscore(DFsub, axis=1), columns=DFsub.columns, index=DFsub.index)\n",
    "    # 3. Add kinase col \n",
    "    newKinaseCol = pd.Series(df['Kinase'], name='Kinase', index=df.index)\n",
    "    zscoreDF = pd.concat([newKinaseCol, zscoreDF ], axis=1)\n",
    "    zscoreDF = zscoreDF.reset_index()\n",
    "    del zscoreDF['index']\n",
    "    return zscoreDF\n",
    "\n",
    "\n",
    "# Convert to zscores\n",
    "# X2K\n",
    "X2K_UP_nLog_zscore = values_to_zscores(X2K_UP)\n",
    "X2K_DN_nLog_zscore = values_to_zscores(X2K_DN)\n",
    "# KEA\n",
    "KEA_UP_nLog_zscore = values_to_zscores(KEA_UP)\n",
    "KEA_DN_nLog_zscore = values_to_zscores(KEA_DN)\n",
    "# sns.distplot(X2K_UP_nLog_zscore.iloc[:,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Values to Ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def values_to_ranks(DF):\n",
    "    #newRanks_DF=pd.DataFrame(index=DF.index)\n",
    "    DF.index = DF['Kinase']\n",
    "    Ranks=[]\n",
    "    # assign ranks based on given value (could be pvalue, -log(pvalue), ranks, etc)\n",
    "    for col in DF.columns[1:]:\n",
    "        #print(col)\n",
    "        # Since zscore comes from -log(pvalue), flip the rank order so that low numbered ranks are still the best\n",
    "        orderedCol = DF[col].sort_values(ascending=False)\n",
    "        \n",
    "        newRanks = pd.Series(data=range(0,len(orderedCol)), name=col, index=orderedCol.index)\n",
    "        newRanks.sort_index(inplace=True) # Sort by index\n",
    "        Ranks.append(newRanks.values)\n",
    "        #newRanks = pd.DataFrame(data=list(range(0,len(orderedCol))), columns=[col], index=orderedCol.index)\n",
    "        # Merge DFs on index\n",
    "        #newRanks_DF = pd.concat([newRanks_DF, newRanks_DF], axis=1)\n",
    "        #newRanks_DF = pd.merge(newRanks_DF, newRanks, left_index=True, right_index=True)\n",
    "        #newRanks_DF.loc[:,col] = newRanks\n",
    "    newRanks_DF = pd.DataFrame(data=np.column_stack(Ranks), columns=DF.columns[1:], index=DF.index)\n",
    "    # Add back kinase col \n",
    "    newKinaseCol = pd.Series(newRanks_DF.index, name='Kinase', index=newRanks_DF.index)\n",
    "    ranks_DF = pd.concat([newKinaseCol, newRanks_DF ], axis=1)\n",
    "    ranks_DF.index = range(0,len(ranks_DF))\n",
    "    return ranks_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -log(pvalues) to Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2K_UP_nLog_ranks = values_to_ranks(X2K_UP)\n",
    "X2K_DN_nLog_ranks = values_to_ranks(X2K_DN)\n",
    "# KEA\n",
    "KEA_UP_nLog_ranks = values_to_ranks(KEA_UP)\n",
    "KEA_DN_nLog_ranks = values_to_ranks(KEA_DN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zscores to Ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2K_UP_nLog_zscore_ranks = values_to_ranks(X2K_UP_nLog_zscore)\n",
    "X2K_DN_nLog_zscore_ranks = values_to_ranks(X2K_DN_nLog_zscore)\n",
    "# KEA\n",
    "KEA_UP_nLog_zscore_ranks = values_to_ranks(KEA_UP_nLog_zscore)\n",
    "KEA_DN_nLog_zscore_ranks = values_to_ranks(KEA_DN_nLog_zscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data group lists\n",
    "negLogPvals = ['X2K_UP','X2K_DN','KEA_UP','KEA_DN']\n",
    "negLogPval_Ranks = ['X2K_UP_nLog_ranks', 'X2K_DN_nLog_ranks', 'KEA_UP_nLog_ranks', 'KEA_DN_nLog_ranks']\n",
    "negLogPval_zScore_Ranks = ['X2K_UP_nLog_zscore_ranks','X2K_DN_nLog_zscore_ranks','KEA_UP_nLog_zscore_ranks','KEA_DN_nLog_zscore_ranks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OFF\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Saving the objects:\n",
    "negLogPvals_VARS = [X2K_DN, X2K_DN, X2K_DN, KEA_UP, KEA_DN]\n",
    "negLogPval_Ranks_VARS = [X2K_UP_nLog_ranks, X2K_DN_nLog_ranks, KEA_UP_nLog_ranks, KEA_DN_nLog_ranks]\n",
    "negLogPval_zScore_Ranks_VARS = [X2K_UP_nLog_zscore_ranks,X2K_DN_nLog_zscore_ranks,KEA_UP_nLog_zscore_ranks,KEA_DN_nLog_zscore_ranks]\n",
    "allVars = negLogPvals_VARS+negLogPval_Ranks_VARS+negLogPval_zScore_Ranks_VARS\n",
    "\n",
    "# def eval_list(varList):\n",
    "#     evalList = []\n",
    "#     for var in varList:\n",
    "#         evalList.append(eval(var))\n",
    "#     return evalList\n",
    "# \n",
    "# negLogPvals_vars = eval_list(negLogPvals)\n",
    "# negLogPval_Ranks_vars = eval_list(negLogPval_Ranks)\n",
    "# negLogPval_zScore_Ranks_vars = eval_list(negLogPval_zScore_Ranks)\n",
    "\n",
    "\n",
    "# Save\n",
    "def save_pickle(name, varList):\n",
    "    with open('Saved_Variables/'+name, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "        pickle.dump(varList, f)\n",
    "save_pickle('allVars.pkl', allVars)\n",
    "save_pickle('negLogPvals_vars.pkl', negLogPvals_vars)\n",
    "save_pickle('negLogPval_Ranks_vars.pkl', negLogPval_Ranks_vars)\n",
    "save_pickle('negLogPval_zScore_Ranks_vars.pkl', negLogPval_zScore_Ranks_vars)\n",
    "\n",
    "# Load\n",
    "def load_pickle(name, varList):\n",
    "    with open('objs.pkl','rb') as f:  # Python 3: open(..., 'rb')\n",
    "       allVars = pickle.load(f)\n",
    "\n",
    "# import processed data\n",
    "import pickle\n",
    "\"\"\"\n",
    "print(\"OFF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustermaps of Kinase Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X2K_UP_nLog_ranks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X2K_DN_nLog_ranks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KEA_UP_nLog_ranks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KEA_DN_nLog_ranks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X2K_UP_nLog_ranks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X2K_DN_nLog_ranks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KEA_UP_nLog_ranks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KEA_DN_nLog_ranks\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(font=\"Arial\")\n",
    "\n",
    "# Color heatmap by kinase groups/families\n",
    "def get_kinase_groups_families():\n",
    "    homo = pd.read_excel('../../X2K_Summaries/General_Resources/Kinase.com/Kinome_Hsap_updated.xls').loc[:,['Name','Group','Family','Subfamily']]\n",
    "    mus = pd.read_excel('../../X2K_Summaries/General_Resources/Kinase.com/Kinome_Mmus.xls').loc[:,['Gene Name','Group','Family','Subfamily']]\n",
    "    mus = mus.rename(columns={'Gene Name':'Name'})\n",
    "    # Fill missing Subfamily info with Family\n",
    "    ##homo['Subfamily'] = homo['Subfamily'].fillna(homo['Family'])\n",
    "    ##mus['Subfamily'] = mus['Subfamily'].fillna(mus['Family'])\n",
    "    \n",
    "    # Capitalize everything\n",
    "    homo = homo.apply(lambda x: x.astype(str).str.upper())\n",
    "    mus = mus.apply(lambda x: x.astype(str).str.upper())\n",
    "    both = pd.concat([homo, mus]).drop_duplicates()\n",
    "    both['Subfamily'] = both['Subfamily'].fillna('[No Info.]')\n",
    "    both.columns = ['Kinase','Kinase_Group','Kinase_Family','Kinase_Subfamily']\n",
    "    both.index = both['Kinase']\n",
    "    return both\n",
    "    \n",
    "def category_colors_dict(category):\n",
    "    KEA_gf = get_kinase_groups_families()\n",
    "    uniqueCats = KEA_gf[category].unique()\n",
    "    colorCodes = sns.color_palette(\"hls\", len(uniqueCats))\n",
    "    colorDict = dict(zip(uniqueCats, colorCodes))\n",
    "    row_colors = KEA_gf[category].map(colorDict)\n",
    "    return row_colors, colorDict\n",
    "\n",
    "def plotHeatmap(DF, method='', z_score=None, category='Kinase_Group', saveFig=True):\n",
    "    DF.dropna(inplace=True)\n",
    "    scaleKey = {None:'raw', 0:'zscore-row', 1:'zscore-col'}\n",
    "    plotDF = DF.iloc[:,1:]\n",
    "    plotDF.index = DF['Kinase']\n",
    "    # Apply z-score tranformation\n",
    "    if z_score==None:\n",
    "        rankMethod = 'Rank'\n",
    "    else:\n",
    "        rankMethod = scaleKey[z_score]\n",
    "        \n",
    "    # CLUSTERMAP\n",
    "    row_colors, colorDict = category_colors_dict(category)\n",
    "    g = sns.clustermap(plotDF, z_score=z_score, row_colors=row_colors, cmap=\"RdBu\" ) #\"inferno\", \"hot\"\n",
    "    # Change label params\n",
    "    g.ax_heatmap.set_title(method +\" : \" + rankMethod, pad=130)\n",
    "    # Set position of main colorbar\n",
    "    g.cax.set_position([.05, .2, .03, .45])\n",
    "    # Draw legend for classes\n",
    "    for label in colorDict.keys():\n",
    "        g.ax_row_dendrogram.bar(0, 0, color=colorDict[label], label=label, linewidth=0)\n",
    "    g.ax_row_dendrogram.legend(loc=\"upper right\", ncol=2, bbox_to_anchor=(.35, 1.35), borderaxespad=1).set_title(category)\n",
    "    # Save fig\n",
    "    if saveFig==True:\n",
    "        g.savefig('Figures/Clustermaps/'+method+'_'+scaleKey[z_score]+'_clustermap.png')\n",
    "\n",
    "\n",
    "def iterate_clustermaps(dfList, z_score=None, category='Kinase_Family', saveFig=False):\n",
    "    for df in dfList:\n",
    "        print(df)\n",
    "        plotHeatmap(DF=eval(df), method=df, z_score=z_score, category=category, saveFig=saveFig)\n",
    "        \n",
    "        \n",
    "# Plot/save clustermap\n",
    "iterate_clustermaps(negLogPval_Ranks, z_score=None, category='Kinase_Group', saveFig=True)\n",
    "iterate_clustermaps(negLogPval_Ranks, z_score=0, category='Kinase_Group', saveFig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layered Rank Distribution Plots "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Every kinase across all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OFF\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "import seaborn as sns  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def kinase_layered_KDE_subplot(dfList):\n",
    "    f, (ax1, ax2) = plt.subplots(2, 2, sharex='all', sharey='all')\n",
    "    for i,df in enumerate(dfList):\n",
    "        print('Plotting all kinase distributions for... ' + df)\n",
    "        DF =  eval(df)\n",
    "        if i<2:\n",
    "            ax=ax1[i]\n",
    "        else:\n",
    "            ax=ax2[i]\n",
    "        for i,row in DF.iterrows():\n",
    "            sns.kdeplot(row.values[1:], label=row[0], cut=0, ax=ax)\n",
    "            plt.title('Kinase rank distributions: '+df)\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.xlabel('Raw Rank')\n",
    "            \n",
    "negLogPval_Ranks\n",
    "kinase_layered_KDE_subplot(dfList=['X2K_UP_nLog_ranks']) #['X2K_UP','X2K_DN','KEA_UP', 'KEA_DN']\n",
    "\n",
    "\"\"\"\n",
    "print(\"OFF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red-cluster kinases from heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nLog_ranks = X2K_DN_nLog_ranks.copy()\n",
    "def get_red_cluster(nLog_ranks_name, threshold=50, save=True):\n",
    "    nLog_ranks = eval(nLog_ranks_name)\n",
    "    nLog_ranks.index = nLog_ranks['Kinase']\n",
    "    # get row/kinase average rank\n",
    "    meanRanks = nLog_ranks.mean(axis=1)\n",
    "    topKinases = list(meanRanks[meanRanks<threshold].sort_values().index)\n",
    "    # Subet DF to just top ranked kinases\n",
    "    topKinases_DF = nLog_ranks[nLog_ranks['Kinase'].isin(topKinases)]\n",
    "    if save==True:\n",
    "        topKinases_DF.to_csv('Results/Red_Clusters/'+nLog_ranks_name+\"_redCluster.csv\", index=False )\n",
    "    return topKinases_DF\n",
    "\n",
    "# X2K \n",
    "X2K_UP_redCluster = get_red_cluster('X2K_UP_nLog_ranks',100)\n",
    "X2K_DN_redCluster = get_red_cluster('X2K_DN_nLog_ranks', 100)\n",
    "#KEA\n",
    "KEA_UP_redCluster = get_red_cluster('KEA_UP_nLog_ranks', 100)\n",
    "KEA_DN_redCluster = get_red_cluster('KEA_DN_nLog_ranks', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap: Ranks of Predicted-Kinases (y-axis) vs. Perturbed-Kinases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustergrammer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:13: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n  del sys.path[0]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "clustergrammer_widget() got an unexpected keyword argument 'network'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-7f21fcbff91a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mclustergrammer_widget\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mDF\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_adjacency_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2K_DN_nLog_ranks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-7f21fcbff91a>\u001b[0m in \u001b[0;36mclustergrammer_widget\u001b[0;34m(DF)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# make interactive widget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mclustergrammer_widget\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mDF\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_adjacency_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2K_DN_nLog_ranks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/clustergrammer_widget/clustergrammer/__init__.py\u001b[0m in \u001b[0;36mwidget\u001b[0;34m(self, which_viz)\u001b[0m\n\u001b[1;32m    208\u001b[0m     '''\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'widget_class'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidget_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidget_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_viz_to_widget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhich_viz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidget_instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: clustergrammer_widget() got an unexpected keyword argument 'network'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from clustergrammer_widget import *\n",
    "\n",
    "def clustergrammer_widget(DF):\n",
    "    ## USING WIDGET\n",
    "    net = Network(clustergrammer_widget)\n",
    "    # load DataFrame\n",
    "    net.load_df(DF)\n",
    "    \n",
    "    # cluster using default parameters\n",
    "    ##net.normalize(axis='row', norm_type='zscore', keep_orig=True)\n",
    "    \n",
    "    # filter for the top 200 rows based on their absolute value sum\n",
    "    ## net.filter_N_top('row', 200, 'sum')\n",
    "    \n",
    "    # cluster using default parameters\n",
    "    net.cluster()\n",
    "    # make interactive widget\n",
    "    net.widget()\n",
    "    \n",
    "clustergrammer_widget( DF=create_adjacency_matrix(X2K_DN_nLog_ranks).iloc[:,1:] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KDE Plot for Target Kinases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'synDict' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a4cb7a5b50f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mAllShuffles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAllShuffles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffledDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mAllSummaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAllShuffles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m \u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_summary_DFs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-a4cb7a5b50f5>\u001b[0m in \u001b[0;36mcombine_summary_DFs\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdfList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# Real data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0msummaryDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargetKinaseRank_SummaryDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mAllSummaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAllSummaries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummaryDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m# Shuffled data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-a4cb7a5b50f5>\u001b[0m in \u001b[0;36mtargetKinaseRank_SummaryDF\u001b[0;34m(DF, method)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mexpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0msyns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msynDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0moverlap\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msyns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Kinase'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# GET SUMMARY TABLE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'synDict' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def rescale_ranks(summaryDF):\n",
    "    # Rescale the ranks from 0-1\n",
    "    ranks = summaryDF[summaryDF['Rank']!='NA']['Rank']\n",
    "    ranks = pd.to_numeric(ranks)\n",
    "    ranks -= ranks.min() \n",
    "    ranks /= ranks.max()\n",
    "    #ranks = ranks.sort_values(ascending=False)\n",
    "    ranks.index = range(0,len(ranks))\n",
    "    summaryDF.index = range(0,len(summaryDF))\n",
    "    summaryDF['Scaled_Ranks'] = ranks\n",
    "    return summaryDF\n",
    "\n",
    "# DF = X2K_DN_negLog_zRank.copy()\n",
    "# method='X2K_DN_negLog_zRank'\n",
    "def targetKinaseRank_SummaryDF(DF, method):\n",
    "    summaryDF = pd.DataFrame()\n",
    "    for col in DF.columns[1:]:\n",
    "        target = col.split(\"_\")[0]\n",
    "        expt = col\n",
    "        syns = synDict[target]\n",
    "        overlap =  set(syns).intersection(set(DF['Kinase']))\n",
    "        # GET SUMMARY TABLE\n",
    "        ## If the target is in the kinse list, put info there\n",
    "        if target in DF['Kinase'].tolist():\n",
    "            targetRank = DF.loc[DF['Kinase']==target, col].values[0]\n",
    "        # If the target's synonym is in the kinase list, put info there\n",
    "        elif len(overlap)>0:\n",
    "            targetRank = DF.loc[DF['Kinase']==list(overlap)[0], col].values[0]\n",
    "        else:\n",
    "            targetRank =\"NA\"\n",
    "            print(expt+': COULD NOT FIND KINASE RANK')\n",
    "        # else:\n",
    "        #     targetRank = 'NA'\n",
    "        newDF = pd.DataFrame(np.column_stack([method, expt, target, targetRank]), columns=['Method','Experiment','Target_Kinase', 'Rank'])\n",
    "        summaryDF = summaryDF.append(newDF)\n",
    "    summaryDF = rescale_ranks(summaryDF)\n",
    "    return summaryDF\n",
    "\n",
    "def getShuffledRanks(DF, method):\n",
    "    shuffledDF = pd.DataFrame()\n",
    "    shuffledCols = list(DF.copy().columns[1:])\n",
    "    shuffle(shuffledCols)\n",
    "    i = 0\n",
    "    for col in DF.columns[1:]:\n",
    "        expt = col\n",
    "        target =  shuffledCols[i].split(\"_\")[0] # FAKE/RANDOM TARGET\n",
    "        syns = synDict[target]\n",
    "        overlap =  set(syns).intersection(set(DF['Kinase']))\n",
    "       \n",
    "        # Get shuffled summary\n",
    "        # GET SUMMARY TABLE\n",
    "        if target in DF['Kinase'].tolist():\n",
    "            targetRank = DF.loc[DF['Kinase']==target, col].values[0]\n",
    "        # Get Synonym's rank\n",
    "        elif len(overlap)>0:\n",
    "            targetRank = DF.loc[DF['Kinase']==list(overlap)[0], col].values[0]\n",
    "        # Otherwise, return NA\n",
    "        else:\n",
    "            targetRank = 'NA'\n",
    "        \n",
    "        #print(target +\" : \"+str(targetRank))\n",
    "        newDF = pd.DataFrame(np.column_stack([method, expt, target, targetRank]), columns=['Method','Experiment','Target_Kinase', 'Rank'])\n",
    "        shuffledDF = shuffledDF.append(newDF)\n",
    "        i+=1\n",
    "    shuffledDF = rescale_ranks(shuffledDF)\n",
    "    return shuffledDF\n",
    "\n",
    "def getPerturbedKinaseRanks_for_every_expt(DF):\n",
    "    oneCol=pd.DataFrame()\n",
    "    df = DF.copy()\n",
    "    perturbedKinases = list(set([x.split('_')[0] for x in list(df.columns)]))\n",
    "    df = df[df['Kinase'].isin(perturbedKinases)]\n",
    "    for col in df.columns[1:]:\n",
    "        actualTarget = col.split('_')[0]\n",
    "        subset = df[df['Kinase']!=actualTarget]\n",
    "        oneCol = pd.concat([oneCol, subset[col]])\n",
    "    # Rescale ranks from 0-1\n",
    "    oneCol -= oneCol.min() \n",
    "    oneCol /= oneCol.max()\n",
    "    return oneCol\n",
    "\n",
    "def allKinase_Ranks(DF):\n",
    "    allRanks=pd.DataFrame()\n",
    "    for col in DF.columns[1:]:\n",
    "        allRanks = pd.concat([allRanks, DF[col]])\n",
    "        #print('Columns Rank Sum = '+str(sum(DF[col])) )\n",
    "    # Rescale ranks from 0-1\n",
    "    allRanks -= allRanks.min() \n",
    "    allRanks /= allRanks.max()\n",
    "    return allRanks\n",
    "\n",
    "\n",
    "def KDE_subplot(dfList, ax, scaledRanks):\n",
    "    if scaledRanks==True:\n",
    "        var = 'Scaled_Ranks'\n",
    "    else:\n",
    "        var = 'Rank'\n",
    "    colorSets = [['magenta', 'm'], ['aqua', 'c'],['r', 'tomato']]\n",
    "    for i,df in enumerate(dfList):\n",
    "        print('Plotting.... '+ df)\n",
    "        DF = eval(df)\n",
    "        # Real Data\n",
    "        summaryDF = targetKinaseRank_SummaryDF(DF, df)\n",
    "        if scaledRanks==False:\n",
    "            summaryDF = summaryDF[summaryDF['Rank']!='NA']\n",
    "            summaryDF = summaryDF[summaryDF['Scaled_Ranks']!='NA']\n",
    "        sns.kdeplot(summaryDF[var], shade=False, label=df, linestyle='-', cut=0, ax=ax, color=colorSets[i][0])\n",
    "        # Shuffled data\n",
    "        shuffledDF = getShuffledRanks(DF, df)\n",
    "        sns.kdeplot(shuffledDF[var], shade=False, label=df+\": Shuffled\", linestyle=\"--\", cut=0, ax=ax, color=colorSets[i][1])\n",
    "        # Just the kinases that were perturbed in the input dataset\n",
    "        sns.kdeplot(getPerturbedKinaseRanks_for_every_expt(DF)[0], shade=False, label=df+': All Perturbed Kinases', linestyle=\"-\", cut=0, ax=ax,\\\n",
    "                    color=colorSets[2][i])\n",
    "    # All kinase ranks (should be uniform)\n",
    "    sns.kdeplot(allKinase_Ranks(DF)[0], shade=False, label='All Kinases', linestyle='-', cut=0, ax=ax, color='black')\n",
    "    ax.legend(loc='center right', ncol=1, fontsize=8) #bbox_to_anchor=(1.25, 0.5) #bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "\n",
    "\n",
    "def layered_negLogPval_KDE(saveFig=True):\n",
    "    f, (ax1, ax2) = plt.subplots(2, 1, sharex='all', sharey='all')\n",
    "    # Make separate X2K and KEA subplots\n",
    "    KDE_subplot(dfList=['X2K_DN'], ax=ax1, scaledRanks=True)#'X2K_UP', \n",
    "    KDE_subplot(dfList=['KEA_DN'], ax=ax2, scaledRanks=True)#'KEA_UP', \n",
    "    if saveFig==True:\n",
    "        plt.draw()\n",
    "        f.savefig('Figures/Distribution_Plots/'+ 'predictedKinase_negLogPval_Distributions.png')\n",
    "        \n",
    "        \n",
    "def layered_KDE_plots(saveFig=True, scaledRanks=False):\n",
    "    f, (ax1, ax2) = plt.subplots(2, 3, sharex='all', sharey=False)#'all')\n",
    "    # Make separate X2K and KEA subplots\n",
    "    KDE_subplot(dfList=['X2K_DN_nLog_ranks'], ax=ax1[0], scaledRanks=scaledRanks) #, 'X2K_DN_Zscore'\n",
    "    KDE_subplot(dfList=['KEA_DN_nLog_ranks'], ax=ax2[0], scaledRanks=scaledRanks) #, 'KEA_DN_Zscore'\n",
    "    KDE_subplot(dfList=['X2K_DN_nLog_zscore_ranks'], ax=ax1[1], scaledRanks=scaledRanks)\n",
    "    KDE_subplot(dfList=['KEA_DN_nLog_zscore_ranks'], ax=ax2[1], scaledRanks=scaledRanks)\n",
    "    KDE_subplot(dfList=['X2K_UP_redCluster'], ax=ax1[2], scaledRanks=scaledRanks)\n",
    "    KDE_subplot(dfList=['X2K_DN_redCluster'], ax=ax2[2], scaledRanks=scaledRanks)\n",
    "    if saveFig==True:\n",
    "        plt.draw()\n",
    "        f.savefig('Figures/Distribution_Plots/'+ 'predictedKinaseRank_Distributions.png')\n",
    "\n",
    "negLogPvals = ['X2K_UP','X2K_DN','KEA_UP','KEA_DN']\n",
    "negLogPval_Ranks = ['X2K_UP_nLog_ranks', 'X2K_DN_nLog_ranks', 'KEA_UP_nLog_ranks', 'KEA_DN_nLog_ranks']\n",
    "negLogPval_zScore_Ranks = ['X2K_UP_nLog_zscore_ranks','X2K_DN_nLog_zscore_ranks','KEA_UP_nLog_zscore_ranks','KEA_DN_nLog_zscore_ranks']\n",
    "\n",
    "# Run\n",
    "## Plot the ranks directly from the sorted -log(pvalue)\n",
    "layered_negLogPval_KDE(saveFig=True)\n",
    "# Plot the ranks from \n",
    "layered_KDE_plots(saveFig=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}