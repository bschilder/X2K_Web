{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Cluster Analyses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%cd Kinase_Enrichment_Comparisons\n",
    "\n",
    "# % cd X2K_Web/Kinase_Enrichment_Comparisons\n",
    "# Choose which file to evaluate\n",
    "gmtPath = '../../X2K_Databases/KINASE/KEA_2018/KEA2018_Mouse-Human_merged_KINASES_unfiltered.gmt'\n",
    "#gmtPath = '../../X2K_Databases/TF/ENCODE_ChEA_Consensus/ENCODE-CHEA_Consensus_UnknownSpecies_TF.gmt'\n",
    "#gmtPath = '../../X2K_Databases/TF/ENCODE_ChEA_Consensus/Processing/ENCODE-CHEA_Consensus_UnknownSpecies_unfiltered_TF.gmt'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import iterations over each Kinase database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pvalueMatrixDict = pickle.load( open( \"Kinase_Enrichment_Comparisons/matrixDict_eachKinaseDB.pkl\", \"rb\" ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjacency Matrix: TF/Kinase Similarity Based on Substrates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def makeSubstrateDict(inputGMT):\n",
    "    with open(inputGMT) as GMT:\n",
    "        gmt = GMT.readlines()\n",
    "    subDict={}\n",
    "    for line in gmt:\n",
    "        lineSp = line.split(\"\\t\")\n",
    "        target = lineSp[0]\n",
    "        substrates = lineSp[2:]\n",
    "        substrates[-1] = substrates[-1].strip(\"\\n\")\n",
    "        subDict[target] = np.array(substrates)\n",
    "    return subDict\n",
    "\n",
    "subDict = makeSubstrateDict(gmtPath)\n",
    "\n",
    "def manual_Jaccard(listA, listB):\n",
    "    Intersection = set(listA).intersection(set(listB))\n",
    "    Union = set(listA).union(set(listB))\n",
    "    return len(Intersection) / len(Union)\n",
    "\n",
    "# Jaccard Index\n",
    "## Dict/array method\n",
    "def jaccard_adjacency_matrix(subDict, saveMatrix=False):\n",
    "    from sklearn.metrics import jaccard_similarity_score\n",
    "    jaccardDict={}\n",
    "    for key in subDict.keys():\n",
    "        print(key)\n",
    "        \n",
    "        jaccardScores=[]\n",
    "        for target in subDict.keys():\n",
    "            #print(target)\n",
    "            np.array(subDict[key])\n",
    "            geneListA = subDict[key]\n",
    "            geneListB =  subDict[target]\n",
    "            \"\"\"\n",
    "            # Make lists the same length by filling shorter one with NAs\n",
    "            NAs = [np.NaN] * abs(len(geneListA)-len(geneListB))\n",
    "            if len(geneListA) > len(geneListB):\n",
    "                geneListB = np.append(geneListB, NAs)\n",
    "            else:\n",
    "                geneListA =  np.append(geneListA, NAs)\n",
    "            # Compute jaccard index\n",
    "            jaccardIndex = jaccard_similarity_score(geneListA, geneListB, normalize=True)\n",
    "            \"\"\"\n",
    "            # Compute jaccard index\n",
    "            jaccardIndex = manual_Jaccard(geneListA, geneListB)\n",
    "            jaccardScores.append(jaccardIndex)\n",
    "        # Add new entry for the key kinase\n",
    "        jaccardDict[key] = dict(zip(subDict.keys(), jaccardScores))\n",
    "    # Construct DF from Dict\n",
    "    jaccardDF = pd.DataFrame.from_dict(jaccardDict)\n",
    "    if saveMatrix!=False:\n",
    "        jaccardDF.to_csv('Results/Adjacency_Matrices/'+saveMatrix+\".txt\", sep=\"\\t\")\n",
    "    return jaccardDF\n",
    "\n",
    "  \n",
    "adjMatrix_name = gmtPath.split(\"/\")[-1].strip('.gmt')\n",
    "# jaccardDF = jaccard_adjacency_matrix(subDict=subDict, saveMatrix=adjMatrix_name)\n",
    "X = adjMatrix = pd.read_table('Results/Adjacency_Matrices/'+ adjMatrix_name +'.txt', index_col=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.cluster import KMeans # shape=(n_samples, n_features)\n",
    "\n",
    "# Determine K:\n",
    "## Elbow method\n",
    "def elbowMethod(X):\n",
    "    distortions = []\n",
    "    K = range(1,10)\n",
    "    for k in K:\n",
    "        kmeanModel = KMeans(n_clusters=k).fit(X)\n",
    "        kmeanModel.fit(X)\n",
    "        distortions.append(sum(np.min(cdist(X, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / X.shape[0])\n",
    "    # Plot the elbow\n",
    "    plt.plot(K, distortions, 'bx-')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Distortion')\n",
    "    plt.title('The Elbow Method showing the optimal k')\n",
    "    return distortions\n",
    "# distortions = elbowMethod(X)\n",
    "\n",
    "def optimalK(data, nrefs=3, maxClusters=15): \n",
    "    # Calculates KMeans optimal K using Gap Statistic from Tibshirani, Walther, Hastie\n",
    "    # Params:\n",
    "    #     data: ndarry of shape (n_samples, n_features)\n",
    "    #     nrefs: number of sample reference datasets to create\n",
    "    #     maxClusters: Maximum number of clusters to test for\n",
    "    # Returns: (gaps, optimalK)\n",
    "    gaps = np.zeros((len(range(1, maxClusters)),))\n",
    "    resultsdf = pd.DataFrame({'clusterCount':[], 'gap':[]})\n",
    "    for gap_index, k in enumerate(range(1, maxClusters)):\n",
    "        print(\"Testing \"+str(gap_index)+\" clusters....\")\n",
    "        # Holder for reference dispersion results\n",
    "        refDisps = np.zeros(nrefs)\n",
    "        # For n references, generate random sample and perform kmeans getting resulting dispersion of each loop\n",
    "        for i in range(nrefs):\n",
    "            # Create new random reference set\n",
    "            randomReference = np.random.random_sample(size=data.shape)\n",
    "            # Fit to it\n",
    "            km = KMeans(k)\n",
    "            km.fit(randomReference)\n",
    "            refDisp = km.inertia_\n",
    "            refDisps[i] = refDisp\n",
    "        # Fit cluster to original data and create dispersion\n",
    "        km = KMeans(k)\n",
    "        km.fit(data)\n",
    "        origDisp = km.inertia_\n",
    "        # Calculate gap statistic\n",
    "        gap = np.log(np.mean(refDisps)) - np.log(origDisp)\n",
    "        # Assign this loop's gap statistic to gaps\n",
    "        gaps[gap_index] = gap\n",
    "        resultsdf = resultsdf.append({'clusterCount':k, 'gap':gap}, ignore_index=True)\n",
    "    return (gaps.argmax() + 1, resultsdf)  # Plus 1 because index of 0 means 1 cluster is optimal, index 2 = 3 clusters are optimal\n",
    "\n",
    "def iterate_optimalK(X):\n",
    "    # get optimal K for raw data\n",
    "    n, gapdf = optimalK(X, nrefs=3, maxClusters=15)\n",
    "    print('Optimal K for raw data is: ', n)\n",
    "    # create KMeans given optimal n and fit\n",
    "    km = KMeans(n_clusters=n)\n",
    "    km.fit(X)\n",
    "    # Find optimal clusters for cluster centers from above\n",
    "    n, gapdf = optimalK(km.cluster_centers_, nrefs=3, maxClusters=len(km.cluster_centers_))\n",
    "    print('Optimal K for first clusters is: ', n)\n",
    "    return n, km\n",
    " \n",
    "n, k_means = iterate_optimalK(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Clustering on Adjacency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-1-365fcf072d2c>, line 47)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-365fcf072d2c>\"\u001b[0;36m, line \u001b[0;32m47\u001b[0m\n\u001b[0;31m    return clustDict\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "def adjacency_matrix_clustering(adjMatrix, nClusters, plot=True):\n",
    "    X = adjMatrix.copy()\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Perform  clustering on adjacency matrix using similar methodology as Clustergrammer\n",
    "    # 1. Calculate cosine similarity \n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    row_similarities = cosine_similarity(X)\n",
    "    col_similarities = cosine_similarity(X.transpose())\n",
    "    # 2. Perform hierarchical clustering\n",
    "    from scipy.cluster.hierarchy import linkage\n",
    "    row_linkage = linkage(row_similarities, method='average')\n",
    "    col_linkage = linkage(col_similarities, method='average')\n",
    "    # 3. Calculate clusters from linkage \n",
    "    from scipy.cluster.hierarchy import fcluster\n",
    "    row_clusters = fcluster(row_linkage, t=nClusters, criterion='maxclust', depth=2, R=None, monocrit=None)\n",
    "    col_clusters = fcluster(col_linkage, t=nClusters, criterion='maxclust', depth=2, R=None, monocrit=None)\n",
    "    # 4. Create colors for each cluster\n",
    "    colors = sns.color_palette(\"hls\", nClusters) #cubehelix\n",
    "    colorDict = dict(zip( range(1, nClusters+1), colors))\n",
    "    row_colors = [colorDict[x] for x in row_clusters]\n",
    "    col_colors = [colorDict[x] for x in col_clusters]\n",
    "    if plot==True:\n",
    "        # 5. Plot\n",
    "        # Hierarchical clustering\n",
    "        g = sns.clustermap(X,  cmap='RdBu', row_linkage=row_linkage, col_linkage=col_linkage, row_colors=row_colors, col_colors=col_colors)\n",
    "        for cluster in colorDict.keys():\n",
    "            color = colorDict[int(cluster)]\n",
    "            g.ax_col_dendrogram.bar(0, 0, color=color, label=cluster, linewidth=0)\n",
    "        g.ax_col_dendrogram.legend(loc=\"center\", ncol=5, title='Cluster', bbox_to_anchor=(.5, 1.35), borderaxespad=1)\n",
    "        plt.title('Normalized Jaccard Index')\n",
    "    return row_clusters, col_clusters\n",
    "\n",
    "row_clusters, col_clusters = adjacency_matrix_clustering(adjMatrix, nClusters=13)\n",
    "\n",
    "# Extract genes from a cluster\n",
    "def extract_genes_from_cluster(X, clusters, save=True):\n",
    "    clustDict={}\n",
    "    for cluster in clusters:\n",
    "        genes = list(X.index[row_clusters==cluster])\n",
    "        clustDict[cluster] = genes\n",
    "    if save==True:\n",
    "        np.save('Results/adjMatrix_clusters/'+adjMatrix_name+'_clustDict.npy', clustDict)\n",
    "    return clustDict\n",
    "\n",
    "clustDict = extract_genes_from_cluster(adjMatrix, set(row_clusters), save=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare genes in red cluster from heatmap to clusters in adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redCluster_vs_adjMatrixClusters(redCluster_name):\n",
    "    redCluster = pd.read_csv('Results/Red_Clusters/'+redCluster_name, index_col=0)\n",
    "    overlapDict={}\n",
    "    redClust_genes = set(redCluster.index)\n",
    "    for c in clustDict.keys():\n",
    "        clust_genes = clustDict[c]\n",
    "        overlap = set(clust_genes).intersection(redClust_genes)\n",
    "        overlapDict[c] = len(overlap) / len(clust_genes) * 100\n",
    "    return overlapDict\n",
    "\n",
    "def plot_cluster_overlap(overlap_Dict, redCluster, ax):\n",
    "    df = pd.DataFrame([overlap_Dict]).T.reset_index()\n",
    "    df.columns = ['Cluster','Percent Overlap']\n",
    "    sns.barplot(data=df, x='Cluster', y='Percent Overlap', ax=ax).set_title(redCluster.strip('.csv'))\n",
    "\n",
    "def subplot_cluster_overlap(redCluster_list):\n",
    "    f, axs =plt.subplots(2, 2, sharex=False, sharey='all')\n",
    "    axs = axs.ravel()\n",
    "    for i,rc in enumerate(redCluster_list):\n",
    "        redCluster_overlap = redCluster_vs_adjMatrixClusters(redCluster_name=rc)\n",
    "        plot_cluster_overlap(overlap_Dict=redCluster_overlap, redCluster=rc, ax=axs[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KINASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KEA 2018\n",
    "redCluster_CSVs = ['X2K_UP_nLog_ranks_redCluster.csv', 'X2K_DN_nLog_ranks_redCluster.csv', \\\n",
    "                   'KEA_UP_nLog_ranks_redCluster.csv', 'KEA_DN_nLog_ranks_redCluster.csv']\n",
    "subplot_cluster_overlap(redCluster_CSVs) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "subplot_cluster_overlap(redCluster_CSVs) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
