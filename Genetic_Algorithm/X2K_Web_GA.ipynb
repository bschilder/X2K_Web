{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# X2K_Web Genetic Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X2K Web API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import http.client\n",
    "import json\n",
    "\n",
    "all_x2k_options = {\n",
    "    'TF-target gene background database used for enrichment': [\n",
    "        'ChEA 2015',\n",
    "        'ENCODE 2015',\n",
    "        'ChEA & ENCODE Consensus',\n",
    "        'Transfac and Jaspar',\n",
    "        'ChEA 2016',\n",
    "        'ARCHS4 TFs Coexp',\n",
    "        'CREEDS',\n",
    "        'Enrichr Submissions TF-Gene Coocurrence',\n",
    "    ],\n",
    "    'kinase interactions to include': [#kea 2016\n",
    "        'kea 2018',\n",
    "        'ARCHS4',\n",
    "        'iPTMnet',\n",
    "        'NetworkIN',\n",
    "        'Phospho.ELM',\n",
    "        'Phosphopoint',\n",
    "        'PhosphoPlus',\n",
    "        'MINT',\n",
    "    ],\n",
    "    'enable_ppi': [\n",
    "        'ppid',\n",
    "        'Stelzl',\n",
    "        'IntAct',\n",
    "        'MINT',\n",
    "        'BioGRID',\n",
    "        'Biocarta',\n",
    "        'BioPlex',\n",
    "        'DIP',\n",
    "        'huMAP',\n",
    "        'InnateDB',\n",
    "        'KEGG',\n",
    "        'SNAVI',\n",
    "        'iREF',\n",
    "        'vidal',\n",
    "        'BIND',\n",
    "        'figeys',\n",
    "        'HPRD',\n",
    "    ],\n",
    "    'max_number_of_interactions_per_article':  {\"10\":15, \"01\":50, \"11\":200, \"00\":1000000},\n",
    "    'max_number_of_interactions_per_protein': {\"10\":50, \"01\":100, \"11\":200, \"00\":500},\n",
    "    'min_network_size': {\"10\":1, \"01\":10, \"11\":50, \"00\":100},\n",
    "    'min_number_of_articles_supporting_interaction': {\"10\":0, \"01\":1, \"11\":5, \"00\":10},\n",
    "    'path_length': {\"0\":1, \"1\":2},\n",
    "    'included organisms in the background database': {\"10\": \"human\", \"01\": \"mouse\", \"11\": \"both\", \"00\": \"RESHUFFLE\"},\n",
    "}\n",
    "\n",
    "def run_X2K(input_genes, x2k_options={}):\n",
    "    # Open HTTP connection\n",
    "    conn = http.client.HTTPConnection(\"amp.pharm.mssm.edu\") #\n",
    "    #conn = http.client.HTTPConnection(\"localhost:8080\", timeout=20)\n",
    "    # Get default options\n",
    "    default_options = {'text-genes': '\\n'.join(input_genes), 'included_organisms': 'both', 'included_database': 'ChEA 2015',\n",
    "                       'path_length': 2, 'minimum network size': 50, 'min_number_of_articles_supporting_interaction': 2,\n",
    "                       'max_number_of_interactions_per_protein': 200, 'max_number_of_interactions_per_article': 100,\n",
    "                       'biocarta': True, 'biogrid': True, 'dip': True, 'innatedb': True, 'intact': True, 'kegg': True, 'mint': True,\n",
    "                       'ppid': True, 'snavi': True, 'number_of_results': 50, 'sort_tfs_by': 'combined score', 'sort_kinases_by': 'combined score',\n",
    "                       'kinase interactions to include': 'kea 2018'}\n",
    "    # Update options\n",
    "    for key, value in x2k_options.items():\n",
    "        if key in default_options.keys() and key != 'text-genes':\n",
    "            default_options.update({key: value})\n",
    "    # Get payload\n",
    "    boundary = \"----WebKitFormBoundary7MA4YWxkTrZu0gW\"\n",
    "    payload = ''.join(['--'+boundary+'\\r\\nContent-Disposition: form-data; name=\\\"{key}\\\"\\r\\n\\r\\n{value}\\r\\n'.format(**locals()) for key, value in default_options.items()])+'--'+boundary+'--'\n",
    "    # Get Headers\n",
    "    headers = {\n",
    "        'content-type': \"multipart/form-data; boundary=\"+boundary,\n",
    "        'cache-control': \"no-cache\",\n",
    "    }\n",
    "    # Initialize connection\n",
    "    conn.request(\"POST\", \"/X2K/api\", payload, headers)\n",
    "    # Get response\n",
    "    res = conn.getresponse()\n",
    "    # Read response\n",
    "    data = res.read().decode('utf-8')\n",
    "    # Convert to dictionary\n",
    "    x2k_results = {key: json.loads(value) if key != 'input' else value for key, value in json.loads(data).items()}\n",
    "    # Clean results\n",
    "    x2k_results['ChEA'] = x2k_results['ChEA']['tfs']\n",
    "    x2k_results['G2N'] = x2k_results['G2N']['network']['nodes']\n",
    "    x2k_results['KEA'] = x2k_results['KEA']['kinases']\n",
    "    x2k_results['X2K'] = x2k_results['X2K']['network']\n",
    "    # Return results\n",
    "    return x2k_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_GEO_line(line):\n",
    "    lineSp = line.split('\\t')\n",
    "    expt_name = lineSp[0]\n",
    "    genes = [str(x.strip(',1.0')) for x in lineSp[2:-1]]\n",
    "    return expt_name, genes\n",
    "\n",
    "def prepare_options_for_x2k(input_genes, x2k_parameters):\n",
    "    options=x2k_parameters.copy()\n",
    "    for param in options:\n",
    "        options[param] = options[param]['selection']\n",
    "    # Add input_genes\n",
    "    options['text-genes'] = input_genes\n",
    "    # Convert ppi into enable flags\n",
    "    for ppi in options['enable_ppi']:\n",
    "        options['enable_' + ppi] = 'true'\n",
    "    del options['enable_ppi']\n",
    "    # Convert any lists\n",
    "    return {\n",
    "        k: '\\n'.join(v) if type(v) == list else str(v)\n",
    "        for k, v in options.items() \n",
    "    }\n",
    "\n",
    "def reshuffle(x2k_parameters):\n",
    "    import random\n",
    "    new_options = x2k_parameters.copy()\n",
    "    for param in new_options:\n",
    "        selection = new_options[param]['selection']\n",
    "        while selection == \"RESHUFFLE\":\n",
    "            selection = random.choice( list(all_x2k_options[param].values()) )\n",
    "            new_options[param]['selection'] = selection\n",
    "    return new_options\n",
    "\n",
    "def translateDatabases(binaryString_segment, _dbs):\n",
    "    selection = []\n",
    "    for i, bit in enumerate(binaryString_segment):\n",
    "        if bit == \"1\":\n",
    "            selection.append(_dbs[i])\n",
    "    return selection\n",
    "\n",
    "def parameters_to_binary(x2k_parameters):\n",
    "    newBinary=[]\n",
    "    for param in all_x2k_options:\n",
    "        newBinary.append( x2k_parameters[param]['bits'] )\n",
    "    return ''.join(newBinary)\n",
    "\n",
    "def binary_to_parameters(binaryString):\n",
    "    x2k_parameters={}\n",
    "    stringCount = 0\n",
    "    for param in all_x2k_options:\n",
    "        # Database lists\n",
    "        if param in ['TF-target gene background database used for enrichment','kinase interactions to include','enable_ppi']:\n",
    "            dbList = all_x2k_options[param]\n",
    "            bitSegment = binaryString[stringCount:stringCount + len(dbList)]\n",
    "            selection = translateDatabases(bitSegment, dbList)\n",
    "            x2k_parameters[param] = {'selection':selection, 'bits':bitSegment}\n",
    "            stringCount += len(selection)\n",
    "        # All other parameters\n",
    "        else:\n",
    "            paramDict = all_x2k_options[param]\n",
    "            bitLength = len(list(paramDict.keys())[0])\n",
    "            bits = binaryString[stringCount:stringCount + bitLength]\n",
    "            selection = paramDict[bits]\n",
    "            x2k_parameters[param] = {'selection':selection, 'bits':bits}\n",
    "            stringCount += bitLength\n",
    "    # Reshuffle\n",
    "    x2k_parameters = reshuffle(x2k_parameters)\n",
    "    newBinary = parameters_to_binary(x2k_parameters)\n",
    "    return x2k_parameters, newBinary\n",
    "    \n",
    " \n",
    "############ Parallel processing of X2K ############\n",
    "def run_X2K_once(x2k_input):\n",
    "    x2k_options = x2k_input['options']\n",
    "    input_genes = x2k_options['text-genes'].split('\\n')\n",
    "    expt_name = x2k_input['expt_name']\n",
    "    try:\n",
    "        #print(expt_name)\n",
    "        x2k_results = run_X2K(input_genes=input_genes, x2k_options=x2k_options)\n",
    "        # x2k_results['x2k_options'] = x2k_options \n",
    "        # x2k_results[expt_name] = x2k_results\n",
    "    except:\n",
    "        #print('Couldnt process '+expt_name)\n",
    "        x2k_results='NA'\n",
    "    return {'experiment':expt_name,'results':x2k_results}\n",
    "\n",
    "def prepare_all_x2k_inputs(binaryString, gmtLines):\n",
    "    all_x2k_inputs=[] \n",
    "    for i,line in enumerate(gmtLines):\n",
    "        expt_name, input_genes = parse_GEO_line(line)\n",
    "        x2k_parameters, newBinary = binary_to_parameters(binaryString)\n",
    "        x2k_options = prepare_options_for_x2k(input_genes, x2k_parameters)\n",
    "        all_x2k_inputs.append( {'options':x2k_options, 'expt_name':expt_name} )\n",
    "    return all_x2k_inputs, newBinary\n",
    "\n",
    "import os\n",
    "def parallel_x2k_results(binaryString, gmtLimit=False):\n",
    "    all_x2k_results = {}\n",
    "    with open('Genetic_Algorithm/testgmt/'+os.listdir('Genetic_Algorithm/testgmt')[0]) as gmt_file:\n",
    "        gmtLines = gmt_file.readlines()\n",
    "    if gmtLimit!=False:\n",
    "        gmtLines = gmtLines[0:gmtLimit]\n",
    "    # Prepare parameters (has to be done iterate\n",
    "    all_x2k_inputs, newBinary = prepare_all_x2k_inputs(binaryString, gmtLines)\n",
    "    \n",
    "    # ********* Parallelize X2K across experiments ********* #\n",
    "    # ****************************************************** #\n",
    "    from multiprocessing.dummy import Pool as ThreadPool\n",
    "    pool = ThreadPool(20)\n",
    "    raw_x2k_results = pool.map(run_X2K_once, all_x2k_inputs)\n",
    "    pool.close() \n",
    "    pool.join() \n",
    "    \n",
    "    # Post-process pooled results\n",
    "    allExpts_x2k_results={}\n",
    "    for dict in raw_x2k_results:\n",
    "        allExpts_x2k_results[ dict['experiment'] ] = dict['results']  \n",
    "    \"\"\"\n",
    "    binaryString=createPopulation(1)[0]\n",
    "    \"\"\"\n",
    "    return all_x2k_results, newBinary\n",
    "\n",
    "\n",
    "def get_x2k_results(binaryString, gmtLimit=False):\n",
    "    import os\n",
    "    allExpts_x2k_results = {}\n",
    "    errors=[]\n",
    "\n",
    "    with open('Genetic_Algorithm/testgmt/'+os.listdir('Genetic_Algorithm/testgmt')[0]) as gmt_file:\n",
    "        gmt = gmt_file.readlines()\n",
    "    if gmtLimit!=False:\n",
    "        gmt = gmt[0:gmtLimit]\n",
    "    for i,line in enumerate(gmt): # PARALLELIZE\n",
    "        # Get experiment name and input genes\n",
    "        expt_name, input_genes = parse_GEO_line(line)\n",
    "        ## Standardize input genes\n",
    "        #input_genes = [standardizeGeneSymbol(g) for g in input_genes]\n",
    "        #print(str(i)+\" : \"+expt_name)\n",
    "        # Prepare options\n",
    "        x2k_parameters, newBinary = binary_to_parameters(binaryString=binaryString)\n",
    "        x2k_options = prepare_options_for_x2k(input_genes, x2k_parameters)\n",
    "        # Run x2k API\n",
    "        try:\n",
    "            x2k_results = run_X2K(input_genes=input_genes, x2k_options=x2k_options)\n",
    "            # Modify results \n",
    "            x2k_results['x2k_options'] = x2k_options\n",
    "            #x2k_results['binaryString'] = binaryString \n",
    "            #x2k_results['newBinary'] = newBinary\n",
    "            allExpts_x2k_results[expt_name] = x2k_results\n",
    "        except:\n",
    "            #print(\"^ couldn't process: skipping\")\n",
    "            errors.append(expt_name) \n",
    "            continue\n",
    "    # print(\"ERRORS: \")\n",
    "    # print(errors)\n",
    "    # print()\n",
    "    return allExpts_x2k_results, newBinary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run X2K GA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GA Support Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# 0. Create initial population\n",
    "###################################\n",
    "def stringLength():\n",
    "    string_length=0\n",
    "    for key in all_x2k_options.keys():\n",
    "        string_length += len(all_x2k_options[key])\n",
    "    return  string_length\n",
    "\n",
    "def createPopulation(popSize):\n",
    "    from random import choice\n",
    "    binaryStringLength = stringLength()\n",
    "    populationinit = []\n",
    "    for i in range(popSize):\n",
    "        populationinit.append(''.join(choice(('0', '1')) for _ in range(binaryStringLength)) )\n",
    "        print(populationinit[i])\n",
    "    return populationinit\n",
    "\n",
    "###################################\n",
    "# 1. Calculate fitness\n",
    "###################################\n",
    "def pvalue_matrix(all_x2k_results, dataType='KEA' ):\n",
    "    nameKey = {'ChEA':'simpleName','KEA':'name', 'G2N':'name'}\n",
    "    ## dict_keys(['X2K', 'ChEA', 'KEA', 'G2N', 'input', 'Experiment', 'x2k_options', 'binaryString'])\n",
    "    # Experiment -> Kinase -> kinase results\n",
    "    pvalDict={} \n",
    "    for expt in all_x2k_results:\n",
    "        results = all_x2k_results[expt][dataType]\n",
    "        if dataType == 'G2N':\n",
    "            for g in results:\n",
    "                g['name'] = g['name'].split(\"-\")[0]\n",
    "        predictedKinases = [y[nameKey[dataType]] for y in results]\n",
    "        predictedPvals = [y['pvalue'] for y in results]\n",
    "        # if replaceNAs==True:\n",
    "        #     predictedPvals = [1.0 if math.isnan(x) else x for x in predictedPvals]\n",
    "        pvalDict[expt] = dict(zip(predictedKinases, predictedPvals))\n",
    "     return pvalDict\n",
    "\n",
    "\n",
    "def population_fitness(gen, population, fitness_method='target_shuffled_difference', fitnessDict={}, gmtLimit=False, parallel=True):\n",
    "    population_results={}\n",
    "    newFitnessDict = fitnessDict.copy()\n",
    "    for i,binaryString in enumerate(population):\n",
    "        unique_id = \"ind\"+str(i)+\"_gen\"+str(gen)\n",
    "        print(unique_id)\n",
    "        if binaryString in newFitnessDict:\n",
    "            print(\"Pulling info from fitnessDict\")\n",
    "            population_results[unique_id] = newFitnessDict[binaryString]\n",
    "        else:\n",
    "            if parallel==True:\n",
    "                all_x2k_results, newBinary = parallel_x2k_results(binaryString=binaryString, gmtLimit=gmtLimit)\n",
    "            else:\n",
    "                all_x2k_results, newBinary = get_x2k_results(binaryString=binaryString, gmtLimit=gmtLimit)\n",
    "\n",
    "            CHEA_pvalDict = pvalue_matrix(all_x2k_results, 'ChEA')\n",
    "            KEA_pvalDict = pvalue_matrix(all_x2k_results, 'KEA')\n",
    "            population_results[unique_id] = {'generation':gen, 'binaryString':binaryString, 'newBinary':newBinary,\n",
    "                                             'fitness':eval(fitness_method)(pd.DataFrame(KEA_pvalDict)), \n",
    "                                             'KEA_results':KEA_pvalDict, 'CHEA_results':CHEA_pvalDict} \n",
    "            #Add to fitness dictionary\n",
    "            newFitnessDict[binaryString] = population_results[unique_id]\n",
    "    return population_results, newFitnessDict\n",
    "\n",
    "###################################\n",
    "# 2. Select fittest individuals\n",
    "###################################\n",
    "def selectFittest(topNum, GA_results, selectionMethod='Fitness-proportional'):\n",
    "    import pandas as pd\n",
    "    fitDF = pd.DataFrame(GA_results).T\n",
    "    import pandas as pd\n",
    "    if selectionMethod == 'Fitness-proportional':\n",
    "        fittestDF = fitDF.sort_values(by=['fitness'],ascending=False).iloc[:topNum,:]\n",
    "        print(\"Top fitnesses:  \" + str(fittestDF[\"fitness\"].values))\n",
    "    # Tournament selection (less stringent)\n",
    "    ## Split the population into equal subgroups, and then select the fittest individual from each group\n",
    "    elif selectionMethod == 'Tournament':\n",
    "        fittestDF=pd.DataFrame()\n",
    "        if fitDF.shape[0] % topNum!=0:\n",
    "            print(\"Tournament selection requires that populationSize/topNum and childrenPerGeneration/topNum are both whole numbers.\")\n",
    "        subsetSize = int( fitDF.shape[0] / topNum )\n",
    "        for t in range(topNum):\n",
    "            subDF = fitDF.sample(n=subsetSize, replace=False)\n",
    "            fittestDF = fittestDF.append( subDF.sort_values(by=['fitness'], ascending=False).iloc[0,:].copy())\n",
    "\n",
    "    elif selectionMethod == 'mixedTournament':\n",
    "        if fitDF.shape[0]%topNum!=0 or topNum%2!=0:\n",
    "            print(\"WARNING:: Tournament selection requires that populationSize/topNum, \\n\"\n",
    "                  +\"childrenPerGeneration/topNum, and topNum/2 to be whole numbers.\")\n",
    "        topNumHalf = int(topNum/2)\n",
    "        sortedDF = fitDF.sort_values(by=['fitness'], ascending=False).copy()\n",
    "        # The first half of the new pop are the fittest parents overall\n",
    "        fittestDF = sortedDF.iloc[:topNumHalf, :].copy()\n",
    "        # Then run Tournament selection on the rest of the population to get the other half of the new pop\n",
    "        everybodyElse = sortedDF.iloc[topNumHalf:, :].copy()\n",
    "        subsetSize = int(everybodyElse.shape[0] / topNumHalf)\n",
    "        for t in range(topNumHalf):\n",
    "            subDF = everybodyElse.sample(n=subsetSize, replace=False)\n",
    "            fittestDF = fittestDF.append(subDF.sort_values(by=['fitness'], ascending=False).iloc[0, :].copy())\n",
    "    else:\n",
    "        print(\"Use viable 'selectionMethod'\")\n",
    "    return fittestDF\n",
    "\n",
    "###################################\n",
    "# 3. Crossover/breed fittest\n",
    "###################################\n",
    "###################################\n",
    "# 4. Introduce random mutations\n",
    "###################################\n",
    "# individual1=  population[0]\n",
    "# individual2=  population[1]\n",
    "# crossoverPoints=8\n",
    "def createChild(individual1, individual2, crossoverPoints, crossoverLocations=\"evenlyDistributed\"):\n",
    "    if crossoverLocations==\"evenlyDistributed\":\n",
    "        chunkSize = int(len(individual1) / (crossoverPoints+1))\n",
    "        ind1Split = [individual1[i:i + chunkSize] for i in range(0, len(individual1), chunkSize)]\n",
    "        ind2Split = [individual2[i:i + chunkSize] for i in range(0, len(individual2), chunkSize)]\n",
    "    elif crossoverLocations=='random':\n",
    "        from random import sample\n",
    "        cutpoints = sorted(sample(range(1, len(individual1)-1), crossoverPoints)) # randomly generate n non-overlapping numbers\n",
    "        def splitParent(parent, cutpoints):\n",
    "            indSplit=[]\n",
    "            for i,num in enumerate(cutpoints):\n",
    "                #print(\"**Cutpoint index= \"+str(i))\n",
    "                if i == 0: # If it's the first cutpoint, take all values up to the first index+1\n",
    "                    start = 0\n",
    "                    end = num\n",
    "                else:\n",
    "                    start = cutpoints[i-1]\n",
    "                    end = num\n",
    "                segment = parent[start:end]\n",
    "                #print(\"Cutpoint= \" + str(start) + \" : \" + str(end))\n",
    "                #print(\"------- \"+segment+\" -------\")\n",
    "                indSplit.append(segment)\n",
    "            # Add the very last segment\n",
    "            indSplit.append(parent[cutpoints[-1]:])\n",
    "            return indSplit\n",
    "        ind1Split = splitParent(individual1, cutpoints)\n",
    "        ind2Split = splitParent(individual2, cutpoints)\n",
    "    # Put together the new child\n",
    "    from random import random\n",
    "    childFragments=[]\n",
    "    for fragment in range(len(ind1Split)):\n",
    "        if int(100*random()) < 50: # Just randomly picks from ParentA or ParentB for each individual parameter\n",
    "            childFragments.append(ind1Split[fragment])\n",
    "        else:\n",
    "            childFragments.append(ind2Split[fragment])\n",
    "    child = \"\".join(childFragments)\n",
    "    return child\n",
    "# child = createChild( fittestDF['newBinary'].values[0] , fittestDF['newBinary'].values[1], 3)\n",
    "\n",
    "def mutateChild(child, mutationRate):\n",
    "    from random import random\n",
    "    mutant = ''\n",
    "    for bit, val in enumerate(child):\n",
    "        rando = random()\n",
    "        if rando <= mutationRate and val == '1':\n",
    "            mutant = str(str(mutant) + '0')\n",
    "        elif rando <= mutationRate and val == '0':\n",
    "            mutant = str(str(mutant) + '1')\n",
    "        else:\n",
    "            mutant = str(str(mutant) + str(val))\n",
    "    return mutant\n",
    "\n",
    "def createChildren(numberOfChildren, fittestDF, mutationRate, breedingVariation, crossoverLocations):\n",
    "    from random import random\n",
    "    fittest = fittestDF.newBinary.tolist()\n",
    "    #breedingChances = []\n",
    "    # Add noise to fitness score?\n",
    "    # for b in range(len(Fittest)):\n",
    "    #     breedingChances.append(np.random.uniform(1 + breedingVariation, 1 - breedingVariation) * int(fittestFitness[b]))\n",
    "    #     topBreeders = [x for _, x in sorted(zip(breedingChances, Fittest), reverse=True)]\n",
    "    # Breed n times\n",
    "    # 'Once you're in, you're in'. After selecting the top fittest individuals, it doesn't matter who is fitter within that group: everyone breeds with everyone else randomly\n",
    "    children = []\n",
    "    for i in range(numberOfChildren):\n",
    "        ind1 = int(random()*len(fittest))\n",
    "        ind2 = int(random()*len(fittest))\n",
    "        child = createChild(fittest[ind1], fittest[ind2], 3, crossoverLocations)\n",
    "        # MUTATE the children!\n",
    "        child = mutateChild(child, mutationRate)\n",
    "        children.append(child)\n",
    "    return children\n",
    "# createChildren(100, fitDF, .01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitness Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# Fitness Support Functions\n",
    "############################\n",
    "def values_to_ranks(DF, ascending=False):\n",
    "    Ranks={}\n",
    "    # assign ranks based on given value (could be pvalue, -log(pvalue), ranks, etc)\n",
    "    for col in DF:\n",
    "        # Since zscore comes from -log(pvalue), flip the rank order so that low numbered ranks are still the best\n",
    "        orderedCol = DF[col].sort_values(ascending=ascending)\n",
    "        # Shuffle order of 0s\n",
    "        nonZeros = orderedCol.loc[orderedCol!=0]\n",
    "        try:\n",
    "            zeros = orderedCol.loc[orderedCol==0].sample(frac=1)\n",
    "        except:\n",
    "            zeros = pd.Series(dtype=float)\n",
    "        shuffledCol = pd.concat([nonZeros, zeros])\n",
    "        # Assign ranks\n",
    "        newRanks = pd.Series(data=range(0,len(shuffledCol)), name=col, index=shuffledCol.index)\n",
    "        newRanks.sort_index(inplace=True) # Sort by index\n",
    "        Ranks[col] = dict(zip(newRanks.index, newRanks.values))\n",
    "    return pd.DataFrame(Ranks)\n",
    "\n",
    "import math\n",
    "def values_to_zscores(DF, dropZeros=True):\n",
    "    zScore_dict={}\n",
    "    if dropZeros==True:\n",
    "        # Drop all rows that ONLY have (0). Never appeared across any experiment\n",
    "        # Keeping the all 0s messes up the zscore\n",
    "        df = DF[(DF.T != math.nan).any()]\n",
    "     else:\n",
    "        df = DF.copy()\n",
    "    for col in df:\n",
    "        zScore_dict[col] = (df[col]-df[col].mean()) / df[col].std(ddof=0)\n",
    "    return pd.DataFrame(zScore_dict)\n",
    "\n",
    "def scaled_ranks(DFstack):\n",
    "    scaledDF = DFstack.copy()\n",
    "    scaledDF['Rank'] -= scaledDF['Rank'].min() \n",
    "    scaledDF['Rank'] /= scaledDF['Rank'].max()\n",
    "    return scaledDF\n",
    "\n",
    "def clearTestGMT():\n",
    "    import os\n",
    "    dir_name = \"Genetic_Algorithm/testgmt/\"\n",
    "    files = os.listdir(dir_name)\n",
    "    for item in files:\n",
    "        if item.endswith(\".txt\") or item.endswith(\".gmt\"):\n",
    "            os.remove(os.path.join(dir_name, item))\n",
    "\n",
    "\n",
    "    \n",
    "############################\n",
    "# Fitness Functions\n",
    "############################\n",
    "def target_shuffled_difference(pval_matrix, zscore=True, scaledRanks=True):\n",
    "    # Select ranking method \n",
    "    if zscore==True:\n",
    "        DF = values_to_zscores(pval_matrix)\n",
    "    else:\n",
    "        DF = values_to_ranks(pval_matrix)\n",
    "    # Calculate the difference between Rank_target and Shuffled_Rank\n",
    "    DFstack = DF.stack().reset_index()\n",
    "    DFstack.columns = ['Kinase','Experiment','Rank']\n",
    "    if scaledRanks==True:\n",
    "            DFstack = scaled_ranks(DFstack)\n",
    "    # Target Kinases Only\n",
    "    DFstack_target = DFstack.loc[DFstack['Kinase']==DFstack['Experiment'].str.split('_').str[0]]\n",
    "    # Shuffled targets\n",
    "    DFstack_shuffled = DFstack_target.copy()\n",
    "    DFstack_shuffled.loc[:,['Experiment','Rank']] = DFstack.sample(n=len(DFstack_target)).loc[:,['Experiment','Rank']].values\n",
    "    DFmerged = pd.merge(DFstack_target, DFstack_shuffled, on='Kinase',suffixes=['_target', '_shuffled'])\n",
    "    fitness = DFmerged['Rank_shuffled'].sum() - DFmerged['Rank_target'].sum()\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GA Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def X2K_Web_GA(GMT, gmtLimit, initial_pop_size=5, generations=5, select_fittest=5, selection_method='Fitness-proportional',\\\n",
    "               fitness_method='target_shuffled_difference', children_per_generation=8, mutation_rate=.01, breeding_variation=0, \\\n",
    "               crossover_locations='random', include_fittest_parents=2, parallel=True, save_results='No'):\n",
    "    # Prepare GMT input\n",
    "    from shutil import copyfile\n",
    "    clearTestGMT()\n",
    "    copyfile(GMT, \"Genetic_Algorithm/testgmt/\"+ GMT.split(\"/\")[-1])\n",
    "    # Store GA settings\n",
    "    GA_settings = {'gmt_file':GMT.split(\"/\")[-1], 'initial_pop_size':initial_pop_size, 'generations':generations, 'select_fittest':select_fittest,\n",
    "                   'selection_method':selection_method}\n",
    "    # Results Dicts\n",
    "    all_GA_results={}\n",
    "    fitnessDict={}\n",
    "    # 0. Create initial population \n",
    "    population = createPopulation(initial_pop_size)\n",
    "    # Loop over n generations\n",
    "    for gen in range(generations):\n",
    "        print('================ GENERATION '+str(gen)+' ================')\n",
    "        # 1. Get all fitnesses \n",
    "        pop_fitness_results, fitnessDict = population_fitness(gen, population, fitness_method, \\\n",
    "                                                     fitnessDict=fitnessDict, gmtLimit=gmtLimit, parallel=parallel)\n",
    "        all_GA_results.update(pop_fitness_results)\n",
    "        # 2. Select fittest\n",
    "        fitnessDF = selectFittest(topNum=select_fittest, GA_results=pop_fitness_results, selectionMethod=selection_method)\n",
    "        # 3. Create/mutate children\n",
    "        population = createChildren(children_per_generation, fitnessDF, mutation_rate, breeding_variation, crossover_locations)\n",
    "        if include_fittest_parents > 0:\n",
    "            # When this is mixedTournament, selects from the parents that bred (regardless of whether they were the fittest in the whole population)\n",
    "            population.extend( fitnessDF['newBinary'].values[:include_fittest_parents].tolist() )\n",
    "    ga_resultsDict = {'all_GA_results':all_GA_results, 'GA_settings':GA_settings}\n",
    "    if save_results!='No':\n",
    "        import pickle \n",
    "        pickle.dump( ga_resultsDict, open( \"Genetic_Algorithm/GA_Results/\"+save_results+\".pkl\", \"wb\" ) )    \n",
    "    return ga_resultsDict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "GAset = {'GMT':\"../X2K_Genetic_Algorithm/Validation/Perturbation_Data/GEO/Kinase_Perturbations_from_GEO_SUBSET1.80per.txt\",\n",
    "                    'gmtLimit':False, 'initial_pop_size':100, 'generations':10, 'select_fittest':10, 'selection_method':'Fitness-proportional',\n",
    "                    'fitness_method':'target_shuffled_difference', 'children_per_generation':92, 'mutation_rate':.01, 'breeding_variation':0,\n",
    "                    'crossover_locations':'random','include_fittest_parents':8, 'parallel':True, 'save_results':'GA_results'}\n",
    "def GA_Train_Test(GAset):\n",
    "    # Train GA\n",
    "    GA_train, GA_settings_train = X2K_Web_GA(GMT=GAset['GMT'], gmtLimit=GAset['gmtLimit'], initial_pop_size=GAset['initial_pop_size'], \\\n",
    "                    generations=GAset['generations'], select_fittest=GAset['select_fittest'], selection_method=GAset['selection_method'], \\\n",
    "                    fitness_method=GAset['fitness_method'], children_per_generation=GAset['children_per_generation'], \\\n",
    "                    mutation_rate=GAset['mutation_rate'], breeding_variation=GAset['breeding_variation'], \\\n",
    "                    crossover_locations=GAset['crossover_locations'], include_fittest_parents=GAset['include_fittest_parents'],\\\n",
    "                    save_results=GAset['save_results']+'_train')\n",
    "    # Test GA\n",
    "    GAset['GMT'] = \"../X2K_Genetic_Algorithm/Validation/Perturbation_Data/GEO/Kinase_Perturbations_from_GEO_SUBSET2.20per.txt\"\n",
    "    GA_test, GA_settings_test = X2K_Web_GA(GMT= GAset['GMT'], gmtLimit=GAset['gmtLimit'], initial_pop_size=GAset['initial_pop_size'], \\\n",
    "                    generations=GAset['generations'], select_fittest=GAset['select_fittest'], selection_method=GAset['selection_method'], \\\n",
    "                    fitness_method=GAset['fitness_method'], children_per_generation=GAset['children_per_generation'], \\\n",
    "                    mutation_rate=GAset['mutation_rate'], breeding_variation=GAset['breeding_variation'], \\\n",
    "                    crossover_locations=GAset['crossover_locations'], include_fittest_parents=GAset['include_fittest_parents'],\\\n",
    "                    save_results=GAset['save_results']+'_test')\n",
    "    import pickle\n",
    "    GA_resultsDict = {'GA_train':GA_train, 'GA_test':GA_test, 'GA_settings_train':GA_settings_train, 'GA_settings_test':GA_settings_test}\n",
    "    pickle.dump( GA_resultsDict, open( \"Genetic_Algorithm/GA_Results/\"+GAset['save_results']+\".pkl\", \"wb\" ) )\n",
    "    \n",
    "    return GA_resultsDict\n",
    "\n",
    "GA_resultsDict = GA_Train_Test(GAset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GA Results Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "GA_results = pickle.load( open( \"Genetic_Algorithm/GA_Results/GA_results.pkl\", \"rb\" ) )\n",
    "\n",
    "\n",
    "def prepare_df(GA_results):\n",
    "    GA_train = GA_results[0]\n",
    "    dat = pd.DataFrame(GA_train).T\n",
    "    dat[['generation','fitness']] = dat[['generation','fitness']].apply(pd.to_numeric)\n",
    "    return dat\n",
    "    \n",
    "def plot_fitness(GA_results):\n",
    "    dat = prepare_df(GA_results)\n",
    "    # Get peak fitness and add back to parent df\n",
    "    dat = dat.join(dat.groupby('generation')['fitness'].max(), on='generation', rsuffix='_peak')\n",
    "    # Plot\n",
    "    f, ax = plt.subplots(1, 1)\n",
    "    sns.pointplot(data=dat, x='generation', y='fitness', label='Mean Fitness', color='limegreen', ax=ax)\n",
    "    sns.pointplot(data=dat, x='generation', y='fitness_peak', label='Peak Fitness', color='forestgreen', markers='^', ax=ax)\n",
    "    # Add legend \n",
    "    ax.legend(handles=ax.lines[2:] , labels=[\"Mean Fitness\",\"Peak Fitness\" ])\n",
    "\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}